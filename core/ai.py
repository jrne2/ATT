# core/ai.py
import boto3
import os
import json
import time
import uuid
import urllib.request
from botocore.exceptions import ClientError
import re

# --- AWS í´ë¼ì´ì–¸íŠ¸ ì„¤ì • ---
region = os.getenv("AWS_DEFAULT_REGION")
s3_client = boto3.client('s3', region_name=region)
transcribe_client = boto3.client('transcribe', region_name=region)
bedrock_client = boto3.client('bedrock-runtime', region_name=region)
polly_client = boto3.client('polly', region_name=region)
S3_BUCKET_NAME = os.getenv("S3_BUCKET_NAME")

def transcribe_audio(audio_bytes, language_code='en-US'):
    """(STT) ì˜¤ë””ì˜¤ë¥¼ S3ì— ì˜¬ë¦¬ê³  Amazon Transcribeë¡œ í…ìŠ¤íŠ¸ ë³€í™˜"""
    job_name = f"transcribe-job-{uuid.uuid4()}"
    object_key = f"{job_name}.wav"
    transcript_text = ""
    if not S3_BUCKET_NAME:
        print("ì˜¤ë¥˜: S3_BUCKET_NAME í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return "[ìŒì„± ì¸ì‹ ì˜¤ë¥˜: S3 ë²„í‚· ì„¤ì • í•„ìš”]"
    try:
        s3_client.put_object(Bucket=S3_BUCKET_NAME, Key=object_key, Body=audio_bytes)
        media_file_uri = f"s3://{S3_BUCKET_NAME}/{object_key}"
        transcribe_client.start_transcription_job(
            TranscriptionJobName=job_name, Media={'MediaFileUri': media_file_uri},
            MediaFormat='wav', LanguageCode=language_code
        )
        while True:
            status = transcribe_client.get_transcription_job(TranscriptionJobName=job_name)
            job_status = status['TranscriptionJob']['TranscriptionJobStatus']
            if job_status in ['COMPLETED', 'FAILED']: break
            print(f"Transcribe ì‘ì—… ì§„í–‰ ì¤‘... ({job_status})")
            time.sleep(3) # í´ë§ ê°„ê²©
        if job_status == 'COMPLETED':
            transcript_file_uri = status['TranscriptionJob']['Transcript']['TranscriptFileUri']
            try:
                with urllib.request.urlopen(transcript_file_uri) as response:
                    transcript_json = json.loads(response.read())
                    transcript_text = transcript_json['results']['transcripts'][0]['transcript']
            except urllib.error.URLError as e:
                 print(f"Transcribe ê²°ê³¼ URL ì ‘ê·¼ ì˜¤ë¥˜: {e}")
                 transcript_text = "[ìŒì„± ì¸ì‹ ê²°ê³¼ ë¡œë“œ ì‹¤íŒ¨]"
            except KeyError:
                 print(f"Transcribe ê²°ê³¼ JSON í˜•ì‹ ì˜¤ë¥˜")
                 transcript_text = "[ìŒì„± ì¸ì‹ ê²°ê³¼ í˜•ì‹ ì˜¤ë¥˜]"
            except Exception as e: # Catch other potential parsing errors
                 print(f"Transcribe ê²°ê³¼ ì²˜ë¦¬ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜: {e}")
                 transcript_text = "[ìŒì„± ì¸ì‹ ê²°ê³¼ ì²˜ë¦¬ ì˜¤ë¥˜]"
        else:
            print(f"Transcribe ì‘ì—… ì‹¤íŒ¨: {status['TranscriptionJob'].get('FailureReason', 'Unknown error')}")
            transcript_text = "[ìŒì„± ì¸ì‹ ì‹¤íŒ¨]"
    except ClientError as e:
        error_code = e.response.get('Error', {}).get('Code')
        print(f"AWS ì˜¤ë¥˜ ë°œìƒ (Transcribe - {error_code}): {e}")
        transcript_text = f"[ìŒì„± ì¸ì‹ ì˜¤ë¥˜: {error_code}]"
    except Exception as e:
        print(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ (Transcribe): {e}")
        transcript_text = "[ìŒì„± ì¸ì‹ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜]"
    finally:
        try: s3_client.delete_object(Bucket=S3_BUCKET_NAME, Key=object_key)
        except ClientError as e: print(f"S3 íŒŒì¼ ì‚­ì œ ì¤‘ ì˜¤ë¥˜: {e}")
        try: transcribe_client.delete_transcription_job(TranscriptionJobName=job_name)
        except ClientError as e: print(f"Transcribe ì‘ì—… ì‚­ì œ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œ ê°€ëŠ¥): {e}")
    return transcript_text

# --- ğŸ‘‡ ì—¬ê¸°ê°€ ìˆ˜ì •ëœ get_ai_response í•¨ìˆ˜ì…ë‹ˆë‹¤ ---
def get_ai_response(persona, user_prompt, learning_language='English', feedback_language='Korean'):
    """(LLM) Bedrock Claude ëª¨ë¸ë¡œ ì˜ì–´ ì‘ë‹µ ë˜ëŠ” (SSML í”¼ë“œë°±) ìƒì„±, ì ìˆ˜ ë°˜í™˜."""
    model_id = 'anthropic.claude-3-sonnet-20240229-v1:0'; lang_code_map = {'English': 'en-US', 'ì˜ì–´': 'en-US', 'Korean': 'ko-KR', 'í•œêµ­ì–´': 'ko-KR', 'Japanese': 'ja-JP','ì¼ë³¸ì–´': 'ja-JP', 'Spanish': 'es-US', 'ìŠ¤í˜ì¸ì–´': 'es-US'}; learning_language_code = lang_code_map.get(learning_language, 'en-US')

    prompt = f"""
Human: You are an expert AI speech coach evaluating a user's utterance.
The user is practicing their '{persona}' persona in {learning_language}.
Your task is to evaluate the user's last message and provide EITHER a conversational response OR feedback, along with a score. Use SSML for the output text.

**Evaluation Criteria:** Score >= 80 for Persona Alignment & Fluency/Accuracy.

**Decision Logic & Output Format:**

1.  **If utterance is GOOD** (score >= 80):
    - Respond conversationally IN {learning_language} (1-2 sentences). Wrap response in `<speak>` tags. Use `<break time="0.3s"/>` subtly if needed. Do NOT use other SSML tags.
    - Provide a high score (80-100).
    - **Output ONLY:** `RESPONSE:::[Your SSML response in {learning_language}]|||SCORE:::[score]/100`

2.  **If utterance NEEDS IMPROVEMENT** (score < 80):
    - Do NOT respond conversationally. Provide feedback explanation IN {feedback_language}. Include "âœ… ì¶”ì²œ í‘œí˜„:" section with 1-2 examples IN {learning_language}. Wrap ONLY {learning_language} examples with `<lang xml:lang="{learning_language_code}">{learning_language} example</lang>`. Wrap entire feedback in `<speak>` tags. Use `<break time="0.3s"/>` if needed. Do NOT use other SSML tags.
    - Provide a score (0-79).
    - **Output ONLY:** `FEEDBACK:::[Your SSML feedback starting with explanation, then example]|||SCORE:::[score]/100`

**Finally, append the score using the format `|||SCORE:::[score]/100`.**

User's message: "{user_prompt}"
Assistant:"""

    body = json.dumps({"anthropic_version": "bedrock-2023-05-31", "max_tokens": 1024, "messages": [{"role": "user", "content": prompt}]})
    main_output_text, score, is_feedback = "", 0, False
    try:
        response = bedrock_client.invoke_model(body=body, modelId=model_id)
        response_body = json.loads(response.get('body').read())
        full_response_text = response_body['content'][0]['text'].strip()
        print(f"--- Bedrock Raw Response ---\n{full_response_text}\n--------------------------") # ë””ë²„ê¹…ìš©

        score_part_found = False
        raw_main_output = full_response_text # ê¸°ë³¸ê°’ ì„¤ì •

        if "|||SCORE:::" in full_response_text:
            parts = full_response_text.split("|||SCORE:::")
            if len(parts) == 2:
                raw_main_output = parts[0].strip(); score_part = parts[1]; score_text = score_part.split('/')[0].strip()
                try: score = int(score_text); score_part_found = True
                except ValueError: print(f"ì ìˆ˜ íŒŒì‹± ì˜¤ë¥˜: '{score_text}'")
            else: print("ì ìˆ˜ íŒŒì‹± ì˜¤ë¥˜: ë¶„ë¦¬ ì‹¤íŒ¨")
        else: print("ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜: '|||SCORE:::' êµ¬ë¶„ì ì—†ìŒ")

        if not score_part_found: score = 0 # ì ìˆ˜ íŒŒì‹± ì‹¤íŒ¨ ì‹œ 0ì 

        # [ìˆ˜ì •ëœ ë¶€ë¶„] í”¼ë“œë°± ì—¬ë¶€ íŒë‹¨ ë¡œì§ ë³´ê°•
        if raw_main_output.startswith("FEEDBACK:::"):
            is_feedback = True
            main_output_text = raw_main_output.replace("FEEDBACK:::", "").strip()
        elif raw_main_output.startswith("RESPONSE:::"):
            is_feedback = False
            main_output_text = raw_main_output.replace("RESPONSE:::", "").strip()
        # ë§ˆì»¤ê°€ ì—†ë”ë¼ë„, ì ìˆ˜ê°€ 80ì  ë¯¸ë§Œì´ë©´ í”¼ë“œë°±ìœ¼ë¡œ ê°„ì£¼ (Fallback ê°•í™”)
        elif score < 80:
             is_feedback = True
             main_output_text = raw_main_output # ë§ˆì»¤ ì—†ìœ¼ë‹ˆ ì „ì²´ í…ìŠ¤íŠ¸ ì‚¬ìš©
             print("ê²½ê³ : ì‘ë‹µ ë§ˆì»¤ ì—†ìŒ, ì ìˆ˜(<80) ê¸°ì¤€ìœ¼ë¡œ í”¼ë“œë°± íŒë‹¨.")
        # ë§ˆì»¤ê°€ ì—†ê³  ì ìˆ˜ê°€ 80ì  ì´ìƒì´ë©´ ì‘ë‹µìœ¼ë¡œ ê°„ì£¼
        else:
             is_feedback = False
             main_output_text = raw_main_output # ë§ˆì»¤ ì—†ìœ¼ë‹ˆ ì „ì²´ í…ìŠ¤íŠ¸ ì‚¬ìš©
             print("ê²½ê³ : ì‘ë‹µ ë§ˆì»¤ ì—†ìŒ, ì ìˆ˜(>=80) ê¸°ì¤€ìœ¼ë¡œ ì‘ë‹µ íŒë‹¨.")

    except ClientError as e: print(f"AWS ì˜¤ë¥˜ (Bedrock): {e}"); main_output_text, score, is_feedback = f"Bedrock ì˜¤ë¥˜: {e}", 0, True
    except Exception as e: print(f"ì˜ˆì™¸ ë°œìƒ (Bedrock): {e}"); main_output_text, score, is_feedback = "AI ì‘ë‹µ ì²˜ë¦¬ ì˜¤ë¥˜", 0, True
    return main_output_text, is_feedback, score
# --- get_ai_response í•¨ìˆ˜ ì •ì˜ ë ---

def get_hint(level, conversation_history, learning_language='English'):
    """(LLM) Bedrock Claude ëª¨ë¸ë¡œ ìˆ˜ì¤€ë³„ íŒíŠ¸ ìƒì„±"""
    model_id = 'anthropic.claude-3-sonnet-20240229-v1:0'
    instruction = (f"Provide one simple sentence in {learning_language}..." if level == 'ì´ˆë³´ì'
                   else f"Provide 3-4 keywords in {learning_language}...")
    messages_for_prompt = []; last_role = None
    for msg in conversation_history[-4:]:
        role = "user" if msg.get('role') == "user" else "assistant"; content = msg.get('content')
        if content and role != last_role: messages_for_prompt.append({"role": role, "content": content}); last_role = role
    final_prompt_content = f"Based on history, provide hint.\n**Instruction:** {instruction}\nOnly hint text."
    if not messages_for_prompt or last_role == "assistant": messages_for_prompt.append({"role": "user", "content": final_prompt_content})
    elif last_role == "user": messages_for_prompt[-1]["content"] += "\n\n" + final_prompt_content
    body = json.dumps({"anthropic_version": "bedrock-2023-05-31", "max_tokens": 50, "messages": messages_for_prompt})
    try:
        response = bedrock_client.invoke_model(body=body, modelId=model_id)
        response_body = json.loads(response.get('body').read())
        # [ìˆ˜ì •ëœ ë¶€ë¶„] ë“¤ì—¬ì“°ê¸° ìˆ˜ì •
        if response_body.get('content') and isinstance(response_body['content'], list) and response_body['content'][0].get('type') == 'text':
             return response_body['content'][0]['text'].strip()
        else:
             print(f"ì˜ˆìƒì¹˜ ëª»í•œ Bedrock ì‘ë‹µ í˜•ì‹(Hint): {response_body}")
             return "íŒíŠ¸ í˜•ì‹ ì˜¤ë¥˜."
    except ClientError as e: print(f"AWS ì˜¤ë¥˜ (Hint): {e}"); return "íŒíŠ¸ ìƒì„± ì˜¤ë¥˜."
    except Exception as e: print(f"ì˜ˆì™¸ ë°œìƒ (Hint): {e}"); return "íŒíŠ¸ ìƒì„± ì˜¤ë¥˜."

def text_to_audio(text, language_code='en-US'):
    """(TTS) Amazon Pollyë¡œ SSML í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜"""
    lang_voice_map = { # ì–¸ì–´ ì½”ë“œì™€ Polly VoiceId ë§¤í•‘
        'en-US': 'Joanna', 'ì˜ì–´': 'Joanna',
        'ko-KR': 'Seoyeon', 'í•œêµ­ì–´': 'Seoyeon',
        'ja-JP': 'Kazuha', 'ì¼ë³¸ì–´': 'Kazuha',
        'es-US': 'Lupe', 'ìŠ¤í˜ì¸ì–´': 'Lupe'
    }
    voice_id = lang_voice_map.get(language_code, 'Joanna') # ë§¤í•‘ ì—†ìœ¼ë©´ ì˜ì–´ ê¸°ë³¸ê°’

    # ì…ë ¥ í…ìŠ¤íŠ¸ê°€ ì´ë¯¸ <speak>ìœ¼ë¡œ ê°ì‹¸ì ¸ ìˆëŠ”ì§€ í™•ì¸
    is_ssml = text.strip().startswith('<speak>') and text.strip().endswith('</speak>')
    ssml_text = text if is_ssml else f"<speak>{text}</speak>" # ì•„ë‹ˆë©´ ê¸°ë³¸ íƒœê·¸ ì¶”ê°€

    try:
        response = polly_client.synthesize_speech(
            VoiceId=voice_id, OutputFormat='mp3', Text=ssml_text,
            Engine='neural', LanguageCode=language_code, TextType='ssml' # SSML ì‹œë„
        )
        return response['AudioStream'].read()
    except ClientError as e:
        print(f"AWS ì˜¤ë¥˜ ë°œìƒ (Polly - SSML ì‹œë„, Voice: {voice_id}, Lang: {language_code}): {e}")
        # ì˜¤ë¥˜ ì‹œ ì¼ë°˜ í…ìŠ¤íŠ¸ ì¬ì‹œë„
        try:
            print("SSML ì˜¤ë¥˜ ë°œìƒ, ì¼ë°˜ í…ìŠ¤íŠ¸ë¡œ ì¬ì‹œë„...")
            plain_text = re.sub('<[^>]+>', '', text) # íƒœê·¸ ì œê±°
            response = polly_client.synthesize_speech(
                VoiceId=voice_id, OutputFormat='mp3', Text=plain_text,
                Engine='neural', LanguageCode=language_code, TextType='text'
            )
            return response['AudioStream'].read()
        except Exception as fallback_e: print(f"Polly ì¬ì‹œë„ ì‹¤íŒ¨: {fallback_e}"); return None
    except Exception as e: print(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ (Polly): {e}"); return None