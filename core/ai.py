# core/ai.py
import boto3
import os
import json
import time
import uuid
import urllib.request
from botocore.exceptions import ClientError # ClientError ì„í¬íŠ¸

# --- AWS í´ë¼ì´ì–¸íŠ¸ ì„¤ì • ---
region = os.getenv("AWS_DEFAULT_REGION")
s3_client = boto3.client('s3', region_name=region)
transcribe_client = boto3.client('transcribe', region_name=region)
bedrock_client = boto3.client('bedrock-runtime', region_name=region)
polly_client = boto3.client('polly', region_name=region)

S3_BUCKET_NAME = os.getenv("S3_BUCKET_NAME")

def transcribe_audio(audio_bytes, language_code='en-US'):
    """(STT) ì˜¤ë””ì˜¤ë¥¼ S3ì— ì˜¬ë¦¬ê³  Amazon Transcribeë¡œ í…ìŠ¤íŠ¸ ë³€í™˜"""
    job_name = f"transcribe-job-{uuid.uuid4()}"
    object_key = f"{job_name}.wav"
    transcript_text = ""

    # S3 ë²„í‚· ì´ë¦„ì´ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸
    if not S3_BUCKET_NAME:
        print("ì˜¤ë¥˜: S3_BUCKET_NAME í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return "[ìŒì„± ì¸ì‹ ì˜¤ë¥˜: S3 ë²„í‚· ì„¤ì • í•„ìš”]"

    try:
        s3_client.put_object(Bucket=S3_BUCKET_NAME, Key=object_key, Body=audio_bytes)
        media_file_uri = f"s3://{S3_BUCKET_NAME}/{object_key}"

        transcribe_client.start_transcription_job(
            TranscriptionJobName=job_name,
            Media={'MediaFileUri': media_file_uri},
            MediaFormat='wav',
            LanguageCode=language_code
        )

        while True:
            status = transcribe_client.get_transcription_job(TranscriptionJobName=job_name)
            job_status = status['TranscriptionJob']['TranscriptionJobStatus']
            if job_status in ['COMPLETED', 'FAILED']:
                break
            print(f"Transcribe ì‘ì—… ì§„í–‰ ì¤‘... ({job_status})")
            time.sleep(3) # í´ë§ ê°„ê²©

        if job_status == 'COMPLETED':
            transcript_file_uri = status['TranscriptionJob']['Transcript']['TranscriptFileUri']
            # Transcribe ê²°ê³¼ íŒŒì¼ì— ì ‘ê·¼ ì‹œë„
            try:
                with urllib.request.urlopen(transcript_file_uri) as response:
                    transcript_json = json.loads(response.read())
                    transcript_text = transcript_json['results']['transcripts'][0]['transcript']
            except urllib.error.URLError as e:
                 print(f"Transcribe ê²°ê³¼ URL ì ‘ê·¼ ì˜¤ë¥˜: {e}")
                 transcript_text = "[ìŒì„± ì¸ì‹ ê²°ê³¼ ë¡œë“œ ì‹¤íŒ¨]"
            except KeyError:
                 print(f"Transcribe ê²°ê³¼ JSON í˜•ì‹ ì˜¤ë¥˜")
                 transcript_text = "[ìŒì„± ì¸ì‹ ê²°ê³¼ í˜•ì‹ ì˜¤ë¥˜]"

        else:
            print(f"Transcribe ì‘ì—… ì‹¤íŒ¨: {status['TranscriptionJob'].get('FailureReason', 'Unknown error')}")
            transcript_text = "[ìŒì„± ì¸ì‹ ì‹¤íŒ¨]"

    except ClientError as e:
        error_code = e.response.get('Error', {}).get('Code')
        if error_code == 'AccessDeniedException':
             print(f"AWS ê¶Œí•œ ì˜¤ë¥˜ ë°œìƒ (Transcribe): {e}. IAM ì •ì±…ì„ í™•ì¸í•˜ì„¸ìš”.")
             transcript_text = "[ìŒì„± ì¸ì‹ ì˜¤ë¥˜: ê¶Œí•œ ë¶€ì¡±]"
        else:
             print(f"AWS ì˜¤ë¥˜ ë°œìƒ (Transcribe): {e}")
             transcript_text = "[ìŒì„± ì¸ì‹ ì¤‘ ì˜¤ë¥˜ ë°œìƒ]"
    except Exception as e: # ì˜ˆìƒì¹˜ ëª»í•œ ë‹¤ë¥¸ ì˜¤ë¥˜ ì²˜ë¦¬
        print(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ (Transcribe): {e}")
        transcript_text = "[ìŒì„± ì¸ì‹ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜]"
    finally:
        # S3 íŒŒì¼ ì‚­ì œ ì‹œë„
        try:
            s3_client.delete_object(Bucket=S3_BUCKET_NAME, Key=object_key)
        except ClientError as e:
            print(f"S3 íŒŒì¼ ì‚­ì œ ì¤‘ ì˜¤ë¥˜: {e}")

        # Transcribe ì‘ì—… ì‚­ì œ ì‹œë„ (ì‘ì—…ì´ ì¡´ì¬í•  ê²½ìš°)
        try:
            transcribe_client.delete_transcription_job(TranscriptionJobName=job_name)
        except ClientError as e:
            # ì‘ì—…ì´ ì´ë¯¸ ì™„ë£Œ/ì‹¤íŒ¨ í›„ ìë™ ì‚­ì œë˜ì—ˆê±°ë‚˜, ê¶Œí•œì´ ì—†ì„ ìˆ˜ ìˆìŒ (ë¬´ì‹œ ê°€ëŠ¥)
            print(f"Transcribe ì‘ì—… ì‚­ì œ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œ ê°€ëŠ¥): {e}")

    return transcript_text

# --- ğŸ‘‡ ì—¬ê¸°ê°€ get_ai_response í•¨ìˆ˜ ì •ì˜ ë¶€ë¶„ì…ë‹ˆë‹¤. ---
def get_ai_response(persona, user_prompt, learning_language='English', feedback_language='Korean'):
    """(LLM) Bedrock Claude ëª¨ë¸ë¡œ ì‚¬ìš©ìì˜ ë°œí™”ë¥¼ í‰ê°€í•˜ì—¬,
    ìƒí™©ì— ë§ëŠ” ë‹¨ì¼ í…ìŠ¤íŠ¸(ì˜ì–´ ì‘ë‹µ ë˜ëŠ” í•œêµ­ì–´ í”¼ë“œë°±)ì™€ ì ìˆ˜ë¥¼ ë°˜í™˜."""
    model_id = 'anthropic.claude-3-sonnet-20240229-v1:0'
    prompt = f"""
Human: You are an expert AI speech coach evaluating a user's utterance.
The user is practicing their '{persona}' persona in {learning_language}.

Your task is to evaluate the user's last message based on the criteria below and provide EITHER a conversational response OR feedback, along with a score.

**Evaluation Criteria:**
- Persona Alignment: Does the utterance strongly match the '{persona}' style (tone, confidence, vocabulary)? Score >= 80/100 required.
- Fluency & Accuracy: Is the utterance reasonably fluent and grammatically correct? Minor errors acceptable if communication is clear.

**Decision Logic & Output:**

1.  **If the utterance is GOOD** (meets both criteria well, score >= 80):
    - Respond conversationally IN {learning_language}, in the persona of '{persona}'. Keep it concise (1-2 sentences).
    - Provide a high score (80-100).
    - **Your entire output MUST be ONLY the conversational response text.**

2.  **If the utterance NEEDS IMPROVEMENT** (fails one or both criteria, score < 80):
    - Do NOT provide a conversational response.
    - Provide constructive feedback IN {feedback_language}. Focus on the most critical area. Be specific and actionable.
    - Include an "âœ… ì¶”ì²œ í‘œí˜„:" section. Crucially, the revised sentence example(s) in this section MUST be written IN {learning_language}.
    - Provide a score reflecting the issues (0-79).
    - **Your entire output MUST be ONLY the feedback text (including the recommended expression written in {learning_language}).**

**Finally, append the score on a new line after your main response or feedback, using the format `|||SCORE:::[score]/100`.**

User's message: "{user_prompt}"
Assistant:"""

    body = json.dumps({
        "anthropic_version": "bedrock-2023-05-31",
        "max_tokens": 1024,
        "messages": [{"role": "user", "content": prompt}]
    })

    main_output_text = ""
    score = 0
    is_feedback = False

    try:
        response = bedrock_client.invoke_model(body=body, modelId=model_id)
        response_body = json.loads(response.get('body').read())
        full_response_text = response_body['content'][0]['text'].strip()
        print(f"--- Bedrock Raw Response --- \n{full_response_text}\n--------------------------") # ë””ë²„ê¹…ìš© ì¶œë ¥ ì¶”ê°€

        # [ìˆ˜ì •ëœ ì ìˆ˜ íŒŒì‹± ë¡œì§]
        score_part_found = False
        if "|||SCORE:::" in full_response_text:
            parts = full_response_text.split("|||SCORE:::")
            if len(parts) == 2:
                main_output_text = parts[0].strip()
                score_part = parts[1]
                score_text_parts = score_part.split('/')
                if len(score_text_parts) > 0:
                    score_text = score_text_parts[0].strip()
                    print(f"Extracted score text: '{score_text}'") # ë””ë²„ê¹…ìš© ì¶œë ¥ ì¶”ê°€
                    try:
                        score = int(score_text)
                        score_part_found = True
                        print(f"Parsed score: {score}") # ë””ë²„ê¹…ìš© ì¶œë ¥ ì¶”ê°€
                    except ValueError:
                        print(f"ì ìˆ˜ íŒŒì‹± ì˜¤ë¥˜ (ValueError): '{score_text}'ëŠ” ìˆ«ìê°€ ì•„ë‹˜")
                else:
                     print("ì ìˆ˜ íŒŒì‹± ì˜¤ë¥˜: '/' êµ¬ë¶„ì ì—†ìŒ")
            else:
                print("ì ìˆ˜ íŒŒì‹± ì˜¤ë¥˜: '|||SCORE:::' êµ¬ë¶„ì ë¶„ë¦¬ ì‹¤íŒ¨")
        else:
            print("ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜: '|||SCORE:::' êµ¬ë¶„ì ì—†ìŒ")
            main_output_text = full_response_text # êµ¬ë¶„ì ì—†ìœ¼ë©´ ì „ì²´ë¥¼ ë©”ì¸ í…ìŠ¤íŠ¸ë¡œ

        if not score_part_found:
             score = 0 # ì–´ë–¤ ì´ìœ ë¡œë“  ì ìˆ˜ íŒŒì‹± ì‹¤íŒ¨ ì‹œ 0ì  ì²˜ë¦¬

        # í”¼ë“œë°± ì—¬ë¶€ íŒë‹¨ (ì ìˆ˜ ê¸°ì¤€)
        if score < 80:
            is_feedback = True
        # Bedrock ì‘ë‹µ ì‹œì‘ ë¶€ë¶„ í™•ì¸ (ë” ì •í™•í•œ ë°©ë²•)
        elif main_output_text.startswith("FEEDBACK:::"): # ì‹¤ì œë¡œëŠ” ì´ í”„ë¡¬í”„íŠ¸ëŠ” FEEDBACK::: ë¥¼ ì•ˆë§Œë“¦
             is_feedback = True
        elif main_output_text.startswith("RESPONSE:::"): # ì‹¤ì œë¡œëŠ” ì´ í”„ë¡¬í”„íŠ¸ëŠ” RESPONSE::: ë¥¼ ì•ˆë§Œë“¦
             is_feedback = False
        # ë§Œì•½ RESPONSE/FEEDBACK ë§ˆì»¤ ì—†ì´ ì ìˆ˜ë§Œ 80ì  ë¯¸ë§Œì´ë©´ í”¼ë“œë°±ìœ¼ë¡œ ê°„ì£¼
        elif score < 80:
             is_feedback = True


    except ClientError as e:
        print(f"AWS ì˜¤ë¥˜ ë°œìƒ (Bedrock): {e}")
        main_output_text = f"Bedrock í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"
        score = 0
        is_feedback = True # ì˜¤ë¥˜ëŠ” í”¼ë“œë°±ìœ¼ë¡œ ì²˜ë¦¬
    except Exception as e:
        print(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ (Bedrock): {e}")
        main_output_text = "AI ì‘ë‹µ ì²˜ë¦¬ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ"
        score = 0
        is_feedback = True # ì˜¤ë¥˜ëŠ” í”¼ë“œë°±ìœ¼ë¡œ ì²˜ë¦¬

    # ê²°ê³¼ ë°˜í™˜
    return main_output_text, is_feedback, score

# --- íŒíŠ¸ ìƒì„± í•¨ìˆ˜ ---
def get_hint(level, conversation_history, learning_language='English'):
    """(LLM) Bedrock Claude ëª¨ë¸ë¡œ ìˆ˜ì¤€ë³„ íŒíŠ¸ ìƒì„± (ì—­í•  êµëŒ€ ë³´ì¥)"""
    model_id = 'anthropic.claude-3-sonnet-20240229-v1:0'
    if level == 'ì´ˆë³´ì':
        instruction = f"Provide one complete and simple sentence in {learning_language} that can naturally follow this conversation."
    else:
        instruction = f"Provide 3-4 relevant keywords in {learning_language} that can be used to continue this conversation."

    messages_for_prompt = []
    last_role = None # ë§ˆì§€ë§‰ ì—­í•  ì¶”ì  ë³€ìˆ˜

    # ëŒ€í™” ê¸°ë¡ì„ Claude í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (ìµœê·¼ 4ê°œ í„´)
    for msg in conversation_history[-4:]:
        current_role = "user" if msg['role'] == "user" else "assistant"
        # content í‚¤ê°€ ìˆê³ , ì´ì „ ì—­í• ê³¼ ë‹¤ë¥¼ ë•Œë§Œ ì¶”ê°€
        if 'content' in msg and msg['content'] and current_role != last_role:
             messages_for_prompt.append({"role": current_role, "content": msg['content']})
             last_role = current_role # ë§ˆì§€ë§‰ ì—­í•  ì—…ë°ì´íŠ¸

    # ìµœì¢… ì§€ì‹œì‚¬í•­ ì¶”ê°€
    final_prompt_content = f"""Based on the recent conversation history above, provide a hint for the user.

**Instruction:** {instruction}

Provide only the hint text itself, without any introductory phrases like "Here's a hint:"."""

    # ë§ˆì§€ë§‰ ì—­í• ì´ assistantì˜€ê±°ë‚˜ ë©”ì‹œì§€ê°€ ë¹„ì–´ìˆìœ¼ë©´ userë¡œ ì¶”ê°€
    if not messages_for_prompt or last_role == "assistant":
        messages_for_prompt.append({"role": "user", "content": final_prompt_content})
    # ë§ˆì§€ë§‰ ì—­í• ì´ userì˜€ë‹¤ë©´, ë§ˆì§€ë§‰ user ë©”ì‹œì§€ì— ì§€ì‹œì‚¬í•­ì„ ë§ë¶™ì„ (ë” ì•ˆì „í•œ ë°©ë²•)
    elif last_role == "user":
        messages_for_prompt[-1]["content"] += "\n\n" + final_prompt_content
        # ë§Œì•½ ë§ˆì§€ë§‰ user ë©”ì‹œì§€ì— ì§€ì‹œì‚¬í•­ì„ ë§ë¶™ì´ëŠ” ëŒ€ì‹ 
        # assistant í„´ì„ í•˜ë‚˜ ì„ì˜ë¡œ ë„£ê³  user í„´ì„ ë„£ëŠ” ë°©ë²•ë„ ê³ ë ¤ ê°€ëŠ¥
        # messages_for_prompt.append({"role": "assistant", "content": "Okay."})
        # messages_for_prompt.append({"role": "user", "content": final_prompt_content})


    body = json.dumps({
        "anthropic_version": "bedrock-2023-05-31",
        "max_tokens": 50, # íŒíŠ¸ëŠ” ì§§ê²Œ
        "messages": messages_for_prompt
    })

    try:
        response = bedrock_client.invoke_model(body=body, modelId=model_id)
        response_body = json.loads(response.get('body').read())
        # Claude 3 ëª¨ë¸ ì‘ë‹µ í˜•ì‹ì— ë§ê²Œ content ë¸”ë¡ í™•ì¸
        if response_body.get('content') and isinstance(response_body['content'], list) and response_body['content'][0].get('type') == 'text':
             hint_text = response_body['content'][0]['text']
             return hint_text.strip()
        else:
             print(f"ì˜ˆìƒì¹˜ ëª»í•œ Bedrock ì‘ë‹µ í˜•ì‹(Hint): {response_body}")
             return "íŒíŠ¸ í˜•ì‹ ì˜¤ë¥˜."

    except ClientError as e:
        print(f"AWS ì˜¤ë¥˜ ë°œìƒ (Hint Generation): {e}")
        return "íŒíŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    except Exception as e:
        print(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ (Hint Generation): {e}")
        return "íŒíŠ¸ ìƒì„± ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ."

# --- TTS í•¨ìˆ˜ ---
def text_to_audio(text, language_code='en-US'): # language_codeëŠ” ë°›ì§€ë§Œ í˜„ì¬ëŠ” ì˜ì–´ë§Œ ì²˜ë¦¬
    """(TTS) Amazon Pollyë¡œ í…ìŠ¤íŠ¸ë¥¼ ì˜ì–´ ìŒì„±ìœ¼ë¡œ ë³€í™˜"""
    voice_id = 'Joanna' # í•­ìƒ ì˜ì–´ ëª©ì†Œë¦¬ ì‚¬ìš©

    # SSML íƒœê·¸ê°€ ìˆëŠ”ì§€ ê°„ë‹¨íˆ í™•ì¸ (AIê°€ ìƒì„±í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ëŒ€ë¹„)
    is_ssml = text.strip().startswith('<speak>') and text.strip().endswith('</speak>')
    ssml_text = text if is_ssml else f"<speak>{text}</speak>" # ê¸°ë³¸ íƒœê·¸ ì¶”ê°€

    try:
        response = polly_client.synthesize_speech(
            VoiceId=voice_id,
            OutputFormat='mp3',
            Text=ssml_text,
            Engine='neural',
            # LanguageCode='en-US', # VoiceIdê°€ ì˜ì–´ì´ë¯€ë¡œ ìƒëµ ê°€ëŠ¥
            TextType='ssml' # SSML ì‹œë„
        )
        return response['AudioStream'].read()
    except ClientError as e:
        print(f"AWS ì˜¤ë¥˜ ë°œìƒ (Polly - SSML ì‹œë„): {e}")
        # ì˜¤ë¥˜ ì‹œ ì¼ë°˜ í…ìŠ¤íŠ¸ ì¬ì‹œë„
        try:
            plain_text = re.sub('<[^>]+>', '', text) # ê°„ë‹¨íˆ íƒœê·¸ ì œê±°
            response = polly_client.synthesize_speech(
                VoiceId=voice_id, OutputFormat='mp3', Text=plain_text,
                Engine='neural', TextType='text'
            )
            return response['AudioStream'].read()
        except Exception as fallback_e:
            print(f"Polly ì¬ì‹œë„ ì‹¤íŒ¨: {fallback_e}")
            return None
    except Exception as e:
        print(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ (Polly): {e}")
        return None