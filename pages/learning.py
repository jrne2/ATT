# pages/learning.py
from dotenv import load_dotenv
load_dotenv()

from core.session import initialize_session, add_message, clear_messages
initialize_session()

import streamlit as st
from core.ai import get_ai_response, transcribe_audio, text_to_audio, get_hint
from streamlit_mic_recorder import mic_recorder
import core.feature_extractor as fe
import re # ì •ê·œ í‘œí˜„ì‹ ì‚¬ìš©

# --- CSS ë“± í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(layout="wide", initial_sidebar_state="collapsed")
st.markdown(
    """
<style>
    [data-testid="SidebarNav"] { display: none; }
    [data-testid="stSidebar"] { display: none; }
    .stChatFloatingInputContainer { bottom: 0px; }
</style>
""",
    unsafe_allow_html=True,
)

# --- ìë™ ê¸°ë¡ ì´ˆê¸°í™” ë° ì„¸ì…˜ ìƒíƒœ ---
if st.session_state.get('start_new_session', False):
    clear_messages(); st.session_state.start_new_session = False
    st.session_state.last_processed_audio_id = None
if 'last_processed_audio_id' not in st.session_state: st.session_state.last_processed_audio_id = None

# --- í˜ì´ì§€ ìƒë‹¨ ì„¤ì •ê°’ ì •ì˜ ---
language_options = {'ì˜ì–´': 'en-US'}
selected_language_name = st.selectbox("í•™ìŠµ ì–¸ì–´:", options=list(language_options.keys()), key="lang_select_main")
selected_language_code = language_options[selected_language_name]
user_level_choice = st.radio("íŒíŠ¸ ìˆ˜ì¤€:", ["ì´ˆë³´ì", "ì¤‘ê¸‰ì"], index=1, horizontal=True, key="level_radio_main")

st.title("ğŸ’¬ í•™ìŠµí•˜ê¸°")

# --- ì„¤ì • ë° ì¡°ì‘ ì˜ì—­ (Expander) ---
with st.expander("ğŸ¤ ìŒì„± ì…ë ¥ ë° íŒíŠ¸ ë³´ê¸°", expanded=True):
    st.write(f"**í˜„ì¬ ì„¤ì •:** í˜ë¥´ì†Œë‚˜ '{st.session_state.persona}', ì–¸ì–´ '{selected_language_name}', íŒíŠ¸ ìˆ˜ì¤€ '{user_level_choice}'")
    st.divider()
    col1, col2 = st.columns([3, 1])
    with col1:
        st.write("**ìŒì„± ì…ë ¥ (ë…¹ìŒ ì¤‘ì§€ ì‹œ ìë™ ë¶„ì„):**")
        audio_info = mic_recorder(start_prompt="ğŸ¤ ë…¹ìŒ ì‹œì‘", stop_prompt="â¹ï¸ ë…¹ìŒ ì¤‘ì§€", key='recorder', format="wav", use_container_width=True)

        if audio_info and audio_info['id'] != st.session_state.get('last_processed_audio_id'):
            st.audio(audio_info['bytes'], format="audio/wav")
            wav_bytes = audio_info['bytes']
            st.session_state.last_processed_audio_id = audio_info['id']

            with st.spinner("AIê°€ ë¶„ì„ ì¤‘..."):
                user_prompt_from_audio = transcribe_audio(wav_bytes, language_code=selected_language_code)
                if user_prompt_from_audio and not user_prompt_from_audio.startswith("[ìŒì„± ì¸ì‹"):
                    add_message("user", user_prompt_from_audio)
                    complexity = fe.get_complexity_score(user_prompt_from_audio)
                    sentiment = fe.get_sentiment(user_prompt_from_audio)
                    keywords = fe.extract_keywords(user_prompt_from_audio)

                    main_output_text, is_feedback, score = get_ai_response(st.session_state.persona, user_prompt_from_audio, learning_language=selected_language_name)

                    if st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
                        st.session_state.messages[-1]['features'] = {'complexity': complexity, 'sentiment': sentiment, 'score': score, 'keywords': keywords}

                    # --- ğŸ‘‡ [ìˆ˜ì •ëœ ë¶€ë¶„] TTS ëŒ€ìƒ ì„ ë³„ ë¡œì§ ---
                    ai_audio_bytes = None
                    log_entry = {"role": "assistant"}
                    text_for_tts = "" # TTS ëŒ€ìƒ í…ìŠ¤íŠ¸ ì´ˆê¸°í™”

                    if is_feedback:
                        # í”¼ë“œë°±: ì „ì²´ í…ìŠ¤íŠ¸ ê¸°ë¡, ì¶”ì²œ í‘œí˜„ë§Œ TTS ëŒ€ìƒ
                        log_entry["feedback"] = main_output_text
                        example_match = re.search(r'âœ… ì¶”ì²œ í‘œí˜„:\s*-\s*"([^"]+)"', main_output_text)
                        if example_match:
                             text_for_tts = example_match.group(1) # ì˜ì–´ ì¶”ì²œ í‘œí˜„
                    elif main_output_text:
                        # ì‘ë‹µ: ì „ì²´ í…ìŠ¤íŠ¸ ê¸°ë¡, ì „ì²´ í…ìŠ¤íŠ¸ê°€ TTS ëŒ€ìƒ
                        log_entry["content"] = main_output_text
                        text_for_tts = main_output_text # ì˜ì–´ ì‘ë‹µ ì „ì²´

                    # TTS ìƒì„± (ëŒ€ìƒì´ ìˆì„ ê²½ìš°)
                    if text_for_tts:
                        ai_audio_bytes = text_to_audio(text_for_tts, language_code=selected_language_code)
                        log_entry["audio"] = ai_audio_bytes
                    # --- ìˆ˜ì • ë ---

                    st.session_state.messages.append(log_entry)
                    st.rerun()
                else:
                    st.error(f"ìŒì„± ì¸ì‹ ì‹¤íŒ¨/ì˜¤ë¥˜: {user_prompt_from_audio}")

    with col2: # íŒíŠ¸ ë²„íŠ¼ ì»¬ëŸ¼
        st.write("**ë„ì›€ ë°›ê¸°:**");
        if st.button("ğŸ’¡ íŒíŠ¸ ë³´ê¸°"):
            if st.session_state.messages:
                with st.spinner("íŒíŠ¸ ìƒì„± ì¤‘..."):
                    hint = get_hint(user_level_choice, st.session_state.messages, learning_language=selected_language_name)
                    st.info(f"íŒíŠ¸ ({user_level_choice}): {hint}")
            else: st.warning("ëŒ€í™”ë¥¼ ë¨¼ì € ì‹œì‘í•´ì£¼ì„¸ìš”.")
st.divider()

# --- ë©”ì¸ ì±„íŒ… UI ---
st.write("ë§ˆì´í¬ë¥¼ ì´ìš©í•´ ìŒì„±ìœ¼ë¡œ ëŒ€í™”í•˜ê±°ë‚˜, ì•„ë˜ ì…ë ¥ì°½ì— í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
if st.session_state.messages:
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            display_text = message.get("feedback") or message.get("content", "")
            if display_text: st.markdown(display_text)
            if "features" in message and message["role"] == "user":
                 st.caption(f"ë¶„ì„: ì ìˆ˜({message['features'].get('score', 'N/A')}), ë³µì¡ë„({message['features'].get('complexity', 0):.1f}), ê°ì„±({message['features'].get('sentiment', 0):.1f})")
            # ì˜¤ë””ì˜¤ ì¬ìƒ (í•­ìƒ ì˜ì–´ ëª©ì†Œë¦¬)
            if "audio" in message and message["role"] == "assistant" and message["audio"]:
                st.audio(message["audio"], format="audio/mp3", autoplay=True)
else: st.info("ìƒˆë¡œìš´ í•™ìŠµ ì„¸ì…˜ì…ë‹ˆë‹¤. ëŒ€í™”ë¥¼ ì‹œì‘í•´ë³´ì„¸ìš”!")

# í…ìŠ¤íŠ¸ ì…ë ¥ ì²˜ë¦¬
if user_prompt := st.chat_input("í…ìŠ¤íŠ¸ ë©”ì‹œì§€ë¥¼ ì…ë ¥í•´ë³´ì„¸ìš”..."):
    add_message("user", user_prompt)
    with st.spinner("AIê°€ ë¶„ì„ ì¤‘..."):
        complexity = fe.get_complexity_score(user_prompt); sentiment = fe.get_sentiment(user_prompt)
        main_output_text, is_feedback, score = get_ai_response(st.session_state.persona, user_prompt, learning_language=selected_language_name)
        if st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
             st.session_state.messages[-1]['features'] = {'score': score, 'complexity': complexity, 'sentiment': sentiment}

        # --- ğŸ‘‡ [ìˆ˜ì •ëœ ë¶€ë¶„] TTS ëŒ€ìƒ ì„ ë³„ ë¡œì§ (í…ìŠ¤íŠ¸ ì…ë ¥) ---
        ai_audio_bytes = None; log_entry = {"role": "assistant"}
        text_for_tts = ""
        if is_feedback:
            log_entry["feedback"] = main_output_text
            example_match = re.search(r'âœ… ì¶”ì²œ í‘œí˜„:\s*-\s*"([^"]+)"', main_output_text)
            if example_match:
                 text_for_tts = example_match.group(1)
        elif main_output_text:
            log_entry["content"] = main_output_text
            text_for_tts = main_output_text
        if text_for_tts:
            ai_audio_bytes = text_to_audio(text_for_tts, language_code=selected_language_code)
            log_entry["audio"] = ai_audio_bytes
        # --- ìˆ˜ì • ë ---

        st.session_state.messages.append(log_entry)
        st.rerun()
st.divider()
if st.button("ğŸ  **ëŒ€ì‹œë³´ë“œë¡œ ëŒì•„ê°€ê¸°**", use_container_width=True): st.switch_page("app.py")