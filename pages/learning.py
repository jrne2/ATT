# pages/learning.py
from dotenv import load_dotenv
load_dotenv() # í˜ì´ì§€ ì‹œì‘ ì‹œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ

from core.session import initialize_session, add_message, clear_messages
initialize_session() # ì„¸ì…˜ ì´ˆê¸°í™” í™•ì¸

import streamlit as st
from core.ai import get_ai_response, transcribe_audio, text_to_audio, get_hint
from streamlit_mic_recorder import mic_recorder
import core.feature_extractor as fe
import core.analyzer as an # analyzer ëª¨ë“ˆ import

# --- CSS ì£¼ì… ì½”ë“œ (ì‚¬ì´ë“œë°” ìˆ¨ê¹€) ---
st.set_page_config(layout="wide", initial_sidebar_state="collapsed")
st.markdown(
    """
<style>
    [data-testid="SidebarNav"] {
        display: none;
    }
    [data-testid="stSidebar"] {
        display: none;
    }
</style>
""",
    unsafe_allow_html=True,
)
# ---------------------------

# --- ìë™ ê¸°ë¡ ì´ˆê¸°í™” ë¡œì§ ---
if st.session_state.get('start_new_session', False):
    clear_messages()
    st.session_state.start_new_session = False
    st.session_state.last_processed_audio_id = None
    st.session_state.current_diagnosed_level = "ì´ˆë³´ì" # ì„¸ì…˜ ì‹œì‘ ì‹œ ê¸°ë³¸ ìˆ˜ì¤€ ì´ˆê¸°í™”

# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ì²˜ìŒ ë¡œë“œ ì‹œ) ---
if 'last_processed_audio_id' not in st.session_state:
    st.session_state.last_processed_audio_id = None
if 'current_diagnosed_level' not in st.session_state:
    st.session_state.current_diagnosed_level = "ì´ˆë³´ì" # ê¸°ë³¸ ìˆ˜ì¤€

# --- í˜ì´ì§€ ìƒë‹¨: ì„¤ì •ê°’ ì •ì˜ ---
language_options = {'ì˜ì–´': 'en-US'}
selected_language_name = st.selectbox(
    "í•™ìŠµí•  ì–¸ì–´ë¥¼ ì„ íƒí•˜ì„¸ìš”:",
    options=list(language_options.keys()),
    key="lang_select_main"
)
selected_language_code = language_options[selected_language_name]
# [ìˆ˜ì •] ì‚¬ìš©ì ì§ì ‘ ì„ íƒ ë¼ë””ì˜¤ ë²„íŠ¼ ì œê±°

st.title("ğŸ’¬ í•™ìŠµí•˜ê¸°")

# --- 1. ì„¤ì • ë° ì¡°ì‘ ì˜ì—­ (Expander ì‚¬ìš©) ---
with st.expander("ğŸ¤ ìŒì„± ì…ë ¥ ë° íŒíŠ¸ ë³´ê¸°", expanded=True):
    # [ìˆ˜ì •] ìë™ìœ¼ë¡œ ì§„ë‹¨ëœ í˜„ì¬ ìˆ˜ì¤€ì„ í‘œì‹œ
    st.write(f"**í˜„ì¬ ì„¤ì •:** í˜ë¥´ì†Œë‚˜ '{st.session_state.persona}', **ì§„ë‹¨ëœ ìˆ˜ì¤€ '{st.session_state.current_diagnosed_level}'**, ì–¸ì–´ '{selected_language_name}'")
    st.divider()

    col1, col2 = st.columns([3, 1])

    with col1: # ìŒì„± ì…ë ¥ ì»¬ëŸ¼
        st.write("**ìŒì„± ì…ë ¥ (ë…¹ìŒ ì¤‘ì§€ ì‹œ ìë™ ë¶„ì„):**")
        audio_info = mic_recorder(start_prompt="ğŸ¤ ë…¹ìŒ ì‹œì‘", stop_prompt="â¹ï¸ ë…¹ìŒ ì¤‘ì§€", key='recorder', format="wav", use_container_width=True)

        if audio_info and audio_info['id'] != st.session_state.get('last_processed_audio_id'):
            st.audio(audio_info['bytes'], format="audio/wav")
            wav_bytes = audio_info['bytes']
            st.session_state.last_processed_audio_id = audio_info['id']

            with st.spinner("AIê°€ ë¶„ì„ ì¤‘..."):
                user_prompt_from_audio = transcribe_audio(wav_bytes, language_code=selected_language_code)
                if user_prompt_from_audio and not user_prompt_from_audio.startswith("[ìŒì„± ì¸ì‹"):
                    add_message("user", user_prompt_from_audio)

                    # 1. íŠ¹ì§• ì¶”ì¶œ
                    complexity = fe.get_complexity_score(user_prompt_from_audio)
                    sentiment = fe.get_sentiment(user_prompt_from_audio)
                    keywords = fe.extract_keywords(user_prompt_from_audio)

                    # [ìˆ˜ì •] 2. ìë™ ìˆ˜ì¤€ ì§„ë‹¨
                    diagnosed_level = an.diagnose_user_level(complexity, sentiment)
                    # ì§„ë‹¨ëœ ìˆ˜ì¤€ì„ ì„¸ì…˜ ìƒíƒœì— ì €ì¥í•˜ì—¬ ë‹¤ìŒ íŒíŠ¸ ìƒì„± ì‹œ ì‚¬ìš©
                    st.session_state.current_diagnosed_level = diagnosed_level

                    # 3. AI ì‘ë‹µ, í”¼ë“œë°±, ì ìˆ˜ ë°›ê¸°
                    response, feedback, score = get_ai_response(st.session_state.persona, user_prompt_from_audio, learning_language=selected_language_name)

                    # ì‚¬ìš©ì ë©”ì‹œì§€ ë¡œê·¸ì— íŠ¹ì§•, ì ìˆ˜, 'ì§„ë‹¨ëœ ìˆ˜ì¤€' ì¶”ê°€
                    if st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
                        st.session_state.messages[-1]['features'] = {
                            'complexity': complexity,
                            'sentiment': sentiment,
                            'score': score,
                            'keywords': keywords,
                            'diagnosed_level': diagnosed_level # ì§„ë‹¨ëœ ìˆ˜ì¤€ ê¸°ë¡
                        }

                    ai_audio_bytes = text_to_audio(response)
                    st.session_state.messages.append({"role": "assistant", "content": response, "feedback": feedback, "audio": ai_audio_bytes})
                    st.rerun()
                else:
                    st.error(f"ìŒì„± ì¸ì‹ ì‹¤íŒ¨ ë˜ëŠ” ì˜¤ë¥˜: {user_prompt_from_audio}")


    with col2: # íŒíŠ¸ ë²„íŠ¼ ì»¬ëŸ¼
        st.write("**ë„ì›€ ë°›ê¸°:**")
        if st.button("ğŸ’¡ íŒíŠ¸ ë³´ê¸°"):
            if st.session_state.messages:
                with st.spinner("íŒíŠ¸ë¥¼ ìƒì„± ì¤‘..."):
                    # [ìˆ˜ì •] ì‚¬ìš©ìê°€ ì„ íƒí•œ ìˆ˜ì¤€ ëŒ€ì‹ , 'ìë™ìœ¼ë¡œ ì§„ë‹¨ëœ í˜„ì¬ ìˆ˜ì¤€'ì„ ì‚¬ìš©
                    hint = get_hint(st.session_state.current_diagnosed_level, st.session_state.messages, learning_language=selected_language_name)
                    st.info(f"íŒíŠ¸ ({st.session_state.current_diagnosed_level} ìˆ˜ì¤€): {hint}")
            else:
                st.warning("ëŒ€í™”ë¥¼ ë¨¼ì € ì‹œì‘í•´ì£¼ì„¸ìš”.")

st.divider() # ì„¤ì • ì˜ì—­ê³¼ ì±„íŒ…ì°½ ë¶„ë¦¬

# --- 2. ë©”ì¸ ì±„íŒ… UI ---
st.write("ë§ˆì´í¬ë¥¼ ì´ìš©í•´ ìŒì„±ìœ¼ë¡œ ëŒ€í™”í•˜ê±°ë‚˜, ì•„ë˜ ì…ë ¥ì°½ì— í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")

if st.session_state.messages:
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            if "feedback" in message and message["role"] == "assistant":
                st.info(message["feedback"])
            if "audio" in message and message["role"] == "assistant" and message["audio"]:
                st.audio(message["audio"], format="audio/mp3", autoplay=True)
            if "features" in message and message["role"] == "user":
                 # ì§„ë‹¨ëœ ë ˆë²¨ë„ í•¨ê»˜ í‘œì‹œ (ì˜µì…˜)
                 level_info = f", ì§„ë‹¨ ìˆ˜ì¤€: {message['features'].get('diagnosed_level', 'N/A')}"
                 st.caption(f"ë¶„ì„: ì ìˆ˜({message['features'].get('score', 'N/A')}), ë³µì¡ë„({message['features'].get('complexity', 0):.1f}), ê°ì„±({message['features'].get('sentiment', 0):.1f}){level_info}")
else:
    st.info("ìƒˆë¡œìš´ í•™ìŠµ ì„¸ì…˜ì…ë‹ˆë‹¤. ëŒ€í™”ë¥¼ ì‹œì‘í•´ë³´ì„¸ìš”!")

if user_prompt := st.chat_input("í…ìŠ¤íŠ¸ ë©”ì‹œì§€ë¥¼ ì…ë ¥í•´ë³´ì„¸ìš”..."):
    add_message("user", user_prompt)
    with st.spinner("AIê°€ ë¶„ì„ ì¤‘..."):
        # í…ìŠ¤íŠ¸ ì…ë ¥ ì‹œì—ë„ íŠ¹ì§• ì¶”ì¶œ ë° ìˆ˜ì¤€ ì§„ë‹¨ (ì˜µì…˜)
        complexity = fe.get_complexity_score(user_prompt)
        sentiment = fe.get_sentiment(user_prompt)
        diagnosed_level = an.diagnose_user_level(complexity, sentiment)
        st.session_state.current_diagnosed_level = diagnosed_level # ìˆ˜ì¤€ ì—…ë°ì´íŠ¸

        response, feedback, score = get_ai_response(
            st.session_state.persona,
            user_prompt,
            learning_language=selected_language_name,
            feedback_language='Korean'
        )

        # í…ìŠ¤íŠ¸ ì…ë ¥ ì‹œ ì‚¬ìš©ì ë©”ì‹œì§€ ë¡œê·¸ì—ë„ íŠ¹ì§•ê³¼ ì ìˆ˜, ì§„ë‹¨ ìˆ˜ì¤€ ì¶”ê°€
        if st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
             st.session_state.messages[-1]['features'] = {'score': score, 'complexity': complexity, 'sentiment': sentiment, 'diagnosed_level': diagnosed_level}

        ai_audio_bytes = text_to_audio(response)
        st.session_state.messages.append({
            "role": "assistant",
            "content": response,
            "feedback": feedback,
            "audio": ai_audio_bytes
        })
        st.rerun()

# --- 3. ëŒ€ì‹œë³´ë“œë¡œ ëŒì•„ê°€ê¸° ë²„íŠ¼ ---
st.divider()
if st.button("ğŸ  **ëŒ€ì‹œë³´ë“œë¡œ ëŒì•„ê°€ê¸°**", use_container_width=True):
    st.switch_page("app.py")